---
title: "Text Mining"
subtitle: "<br><br>USING TIDY DATA PRINCIPLES"
author: "Filippo Chiarello"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css", "css/footer_plus.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      slideNumberFormat: "%current%"
      ratio: "16:9"
    seal: false  
    includes:
      in_header: header.html
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE,
        width = 80)

# install.packages("xaringan")
# install.packages("devtools")
install.packages("stopwords")
# install.packages("textdata")
# install.packages(c("tidyverse", "tidytext", "gutenbergr"))
devtools::install_github("https://github.com/juliasilge/silgelib")


library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, dpi = 300)
library(tidyverse)
library(tidytext)
library(stopwords)
library(textdata)
library(silgelib)
theme_set(theme_roboto())
```

layout: true

<div class="my-footer"><span>Filippo Chiarello, Ph.D.</span></div> 

---

class: inverse, center, bottom

background-image: url(figs/lib_pic.jpg)
background-size: cover

# WELCOME!

## Text Mining Using Tidy Data Principles

### for Strategic and Competitive Intelligence

---

# Introducing Myself

<img src="figs/myself.jpg" width="150px"/> .large[Filippo Chiarello, Ph.D.]

--

- .large[Researcher, University of Pisa] 

--

- .large[Co-Founder and Member, B4DS Lab (http://b4ds.unipi.it/)]

--

- .large[Co-Founder and CTO, Texty s.r.l. (http://texty.biz/)]

--

- .large[Research Consultant, Errequadro s.r.l. (https://www.errequadrosrl.com/)]

---

## **About the Lessons**

--

- .large[Everything is Designed to make your coding life easier üëæ]

--

- .large[There are no dumb questions üßê]

--

- .large[When you talk, it is preferred to turn your camera on üé•]

--

- .large[Let's keep in touch:]

  - By email: send a message to `filippo.chiarello@unipi.it`
  - Via Linkedin: https://www.linkedin.com/in/filippo-chiarello-2b382770/

---

## Importance of TM and NLP for Companies

--

- .large[When?]

--

- .large[What?]

--

- .large[Where?]

--

- .large[Who?]

--

- .large[WHY?]

---

background-image: url(figs/p_and_p_cover.png)
background-size: cover

class: inverse, center, middle

# HOW??

## TIDY DATA PRINCIPLES + TEXT MINING

---

background-image: url(figs/tidytext_repo.png)
background-size: 800px
background-position: 50% 20%

class: bottom, right

.large[[https://github.com/juliasilge/tidytext](https://github.com/juliasilge/tidytext)]

.large[[https://tidytextmining.com/](https://tidytextmining.com/)]

---

background-image: url(figs/cover.png)
background-size: 450px
background-position: 50% 50%

---

class: middle, center

# <i class="fa fa-github"></i>

# GitHub repo for Text Mining Lessons:

.large[[github.com/FilippoChiarello/text-mining](https://github.com/FilippoChiarello/text-mining)]

---

class: inverse

## Plan for introductory lessons

--

- .large[*Part I*: EDA for text]

--

- .large[*Part II*: Modeling for text]

--

- .large[Log in to RStudio Cloud 

---
class: middle, center

# <i class="fa fa-cloud"></i>

# Go here and log in (free):

.large[[bit.ly/rstudio-text-course](https://rstudio.cloud/spaces/95227/join?access_code=e%2FcgTuSzM5egcw0WiSP3ThXTXjIHYqMaSA6rJb3q)]

---

## Let's install some packages

```{r, eval=FALSE}
install.packages(c("tidyverse", 
                   "tidytext", 
                   "gutenbergr"))
```

---

## **What do we mean by tidy text?**


```{r}
text <- c("Tell all the truth but tell it slant ‚Äî",
          "Success in Circuit lies",
          "Too bright for our infirm Delight",
          "The Truth's superb surprise",
          "As Lightning to the Children eased",
          "With explanation kind",
          "The Truth must dazzle gradually",
          "Or every man be blind ‚Äî")

text
```

---

## **What do we mean by tidy text?**

```{r}
library(tidyverse)

text_df <- tibble(line = 1:8, text = text)

text_df
```

---



## **What do we mean by tidy text?**

```{r}
library(tidytext)

text_df %>%
  unnest_tokens(word, text)        #<<
```

---

## Pop Quiz 

.large[A tidy text dataset typically has]

- .unscramble[more]
- .unscramble[fewer]

.large[rows than the original, non-tidy text dataset.]

---

## **Gathering more data**

.large[You can access the full text of many public domain works from [Project Gutenberg](https://www.gutenberg.org/) using the [gutenbergr](https://ropensci.org/tutorials/gutenbergr_tutorial.html) package.]


```{r}
library(gutenbergr)

full_text <- gutenberg_download(6522)

```

<img src="figs/military.jpg" width="250px"/> 

---

## **Time to tidy your text!**

```{r}
tidy_book <- full_text %>%
  mutate(line = row_number()) %>%
  unnest_tokens(word, text)

tidy_book %>% 
  sample_n(10) %>% 
  glimpse()
```

---

## Pop Quiz 

.large[What do you predict will happen if we run the following code?]

```{r, eval=FALSE}
tidy_book %>%
  count(word, sort = TRUE)
```

---

## Pop Quiz 

.large[What do you predict will happen if we run the following code?

```{r}
tidy_book %>%
  count(word, sort = TRUE)
```


---

## **Stop words**

```{r}
get_stopwords()
```

---

## **Stop words**

```{r}
get_stopwords(language = "es")
```

---

## **Stop words**

```{r}
get_stopwords(language = "pt")
```

---

## **Stop words**

```{r}
get_stopwords(source = "smart")
```

---

## **What are the most common words?**

```{r, eval = FALSE}
tidy_book %>%
  anti_join(get_stopwords(source = "smart")) %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(fct_reorder(word, n), n)) +            #<<
  geom_col() +
  coord_flip()
```


---

```{r, echo=FALSE, fig.height=3.9}
tidy_book %>%
  anti_join(get_stopwords(source = "smart")) %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(fct_reorder(word, n), n)) +
  geom_col(fill = "midnightblue", alpha = 0.9) +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  labs(x = NULL, y = "Number of occurrences")
```

---

background-image: url(figs/p_and_p_cover.png)
background-size: cover

class: inverse, center, middle

# SENTIMENT ANALYSIS
# Using lexicons

---

## **Sentiment lexicons**

```{r}
get_sentiments("bing")
```

---

## **Implementing sentiment analysis**

```{r}
tidy_book %>%
  inner_join(get_sentiments("bing")) %>%            #<<
  count(sentiment, sort = TRUE)
```


---

## Pop Quiz

.large[What do you predict will happen if we run the following code?]

```{r, eval=FALSE}
tidy_book %>%
  inner_join(get_sentiments("bing")) %>%            
  count(sentiment, word, sort = TRUE)             #<<
```

---

## **Implementing sentiment analysis**

.large[What do you predict will happen if we run the following code?]

```{r }
tidy_book %>%
  inner_join(get_sentiments("bing")) %>%            
  count(sentiment, word, sort = TRUE)             #<<
```

---

## **Implementing sentiment analysis**

```{r, eval = FALSE}
tidy_book %>%
  inner_join(get_sentiments("bing")) %>%
  count(sentiment, word, sort = TRUE) %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup %>%
  ggplot(aes(fct_reorder(word, n),               #<<
             n, 
             fill = sentiment)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ sentiment, scales = "free") 
```

---

class: middle

```{r, echo=FALSE, fig.height=3.9}
tidy_book %>%
  inner_join(get_sentiments("bing")) %>%
  count(sentiment, word, sort = TRUE) %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup %>%
  ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
  geom_col(alpha = 0.9, show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ sentiment, scales = "free") +
  scale_y_continuous(expand = c(0,0)) +
  labs(x = NULL, y = "Number of occurrences")
```

---

background-image: url(figs/p_and_p_cover.png)
background-size: cover

class: inverse, center, middle

# WHAT IS A DOCUMENT ABOUT?
# Using tf-idf metric

---

## **What is a document about?**

- .large[Term frequency]
- .large[Inverse document frequency]

$$idf(\text{term}) = \ln{\left(\frac{n_{\text{documents}}}{n_{\text{documents containing term}}}\right)}$$

### tf-idf is about comparing **documents** within a **collection**.

---

## **Understanding tf-idf**

.large[Make a collection (*corpus*) for yourself

```{r}

full_collection <- gutenberg_download(c(1272, 5614, 15076, 29185, 29186),
                                      meta_fields = "title")
```
---

## **Understanding tf-idf**

.large[Experiment with a collection (*corpus*) for yourself!]

```{r}
full_collection %>% 
  count(title)
```

---

## **Counting word frequencies in your collection**

```{r}
book_words <- full_collection %>%
  unnest_tokens(word, text) %>%        
  count(title, word, sort = TRUE)
```

What do the columns of `book_words` tell us?

---

## **Calculating tf-idf**

```{r}
book_tfidf <- book_words %>%
  bind_tf_idf(word, title, n)
```

---

## **Calculating tf-idf**

```{r}
book_tfidf
```


---

## Pop Quiz

.large[What do you predict will happen if we run the following code? 

```{r, eval=FALSE}
book_tfidf %>%
  arrange(-tf_idf)
```

---

## Pop Quiz

.large[What do you predict will happen if we run the following code? 

```{r}
book_tfidf %>%
  arrange(-tf_idf)
```

---

## **Calculating tf-idf**

```{r, eval = FALSE}
book_tfidf %>%
  group_by(title) %>%
  top_n(10) %>%
  ungroup %>%
  ggplot(aes(fct_reorder(word, tf_idf),               #<<
             tf_idf, 
             fill = title)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~title, scales = "free")
```

---

```{r, echo=FALSE, fig.height=3.9}
book_tfidf %>%
  group_by(title) %>%
  top_n(10) %>%
  ungroup %>%
  ggplot(aes(fct_reorder(word, tf_idf), 
             tf_idf, 
             fill = title)) +
  geom_col(alpha = 0.9, show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~title, scales = "free") +
  scale_y_continuous(expand = c(0,0)) +
  labs(x = NULL, y = "tf-idf")
```


---

## **N-grams... and beyond!**

```{r}
tidy_ngram <- full_text %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)        #<<

tidy_ngram
```

---

## **N-grams... and beyond!**

```{r}
tidy_ngram %>%
  count(bigram, sort = TRUE)
```

---

## Pop Quiz 

.large[How can we remove stop words?]

- .large[Yes!]
- .large[No]

---

## **N-grams... and beyond!**

```{r}
bigram_counts <- tidy_ngram %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%         #<<
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>%
  count(word1, word2, sort = TRUE)
```

---

## **N-grams... and beyond!**

```{r}
bigram_counts
```

---

background-image: url(figs/p_and_p_cover.png)
background-size: cover

class: inverse

## What can you do with n-grams?

- .large[tf-idf of n-grams]

--

- .large[network analysis]

--

- .large[negation]

---

background-image: url(figs/austen-1.png)
background-size: 750px

---

background-image: url(figs/slider.gif)
background-position: 50% 70%

## **What can you do with n-grams?**

### [She Giggles, He Gallops](https://pudding.cool/2017/08/screen-direction/)

---

background-image: url(figs/change_overall-1.svg)
background-size: contain
background-position: center

---


class: left, middle

# Thanks!


Slides created with [**remark.js**](http://remarkjs.com/) and the R package [**xaringan**](https://github.com/yihui/xaringan)
